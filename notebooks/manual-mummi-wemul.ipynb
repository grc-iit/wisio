{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some logs are stored in VAST with some stored in GPFS.\n",
    "\n",
    "Set `log_dir` to `/vast1/` when running the notebook on Quartz, otherwise use `/gpfs1/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_dir = \"/p/gpfs1/iopp/recorder_app_logs/cm1/nodes-32/workflow-4/_parquet\"\n",
    "# log_dir = \"/p/gpfs1/iopp/recorder_app_logs/hacc|/nodes-32/workflow-0/_parquet\"\n",
    "#log_dir = \"/p/gpfs1/iopp/recorder_app_logs/montage/nodes-32/_parquet\"\n",
    "#log_dir = \"/p/gpfs1/iopp/recorder_app_logs/montage_pegasus/nodes-32/_parquet\"\n",
    "# log_dir = \"/p/gpfs1/iopp/recorder_app_logs/lbann-cosmoflow/nodes-32/_parquet\" # FIXME\n",
    "log_dir = \"/p/gpfs1/iopp/recorder_app_logs/mummi-wemul/nodes-32-ppn-32/_parquet\"# FIXME\n",
    "# log_dir = \"/p/gpfs1/iopp/recorder_app_logs/lbann-jag/nodes-32/_parquet\"\n",
    "#log_dir = \"/p/gpfs1/iopp/recorder_app_logs/genome_pegasus/nodes-32/_parquet\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RecorderAnalyzer` is the main part that initializes the cluster. It creates `LocalCluster` or `LSFCluster` depending on the `force_local` variable. When it is set to `true`, it will just create a `LocalCluster`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from wisio.recorder import VIEW_TYPES, RecorderAnalyzer\n",
    "\n",
    "recorder_analyzer = RecorderAnalyzer(\n",
    "    cluster_manager_args=dict(\n",
    "#         force_local=True,\n",
    "        cluster_settings=dict(\n",
    "#             cores=32,\n",
    "            dashboard_port=3646,\n",
    "            local_directory=\"/var/tmp/dask-recorder\",\n",
    "            log_file=\"%J.log\",\n",
    "#             memory=3200,\n",
    "            worker_queue=\"pdebug\"\n",
    "        )\n",
    "    ),\n",
    "    working_dir='.recorder',\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "recorder_analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[client.dashboard_link for client in recorder_analyzer.cluster_manager.clients]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point on, every step is exactly the same within the `analyze_parquet` method of `RecorderAnalyzer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "global_min_max = recorder_analyzer.load_global_min_max(log_dir=log_dir)\n",
    "global_min_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from wisio._recorder.analysis import (\n",
    "    compute_main_view,\n",
    "    compute_max_io_time,\n",
    "    compute_view\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compute_main_view` automatically does `persist` before returning the DataFrame. You may play with that part if the `main_view` doesn't fit within the allocated memory. That said, `persist`ing it increases performance significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "main_view = compute_main_view(\n",
    "    log_dir=log_dir,\n",
    "    global_min_max=global_min_max,\n",
    "    view_types=VIEW_TYPES\n",
    ")\n",
    "\n",
    "main_view\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_io_time` is just a `dd.Scalar` since I tried to compute everyting lazily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "max_io_time = compute_max_io_time(main_view=main_view)\n",
    "max_io_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may configure `delta` and `cut` using the following variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA = 0.0001\n",
    "CUT = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is how all the views (including `expanded_view` and `bottleneck_view`-I didn't like the `cut_view` name). So, if you want to play with that part `compute_view` is the method you should look for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "def _view_permutations(r: int):\n",
    "    return it.permutations(VIEW_TYPES, r + 1)\n",
    "\n",
    "views = {}\n",
    "for view_permutation in it.chain.from_iterable(map(_view_permutations, range(len(VIEW_TYPES)))):\n",
    "    # Compute view\n",
    "    views[view_permutation] = compute_view(\n",
    "        main_view=main_view,\n",
    "        views=views,\n",
    "        view_permutation=view_permutation,\n",
    "        max_io_time=max_io_time,\n",
    "        delta=DELTA,\n",
    "        cut=CUT\n",
    "    )\n",
    "\n",
    "\n",
    "len(views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following just initializes the bottleneck detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from wisio._recorder.bottlenecks import RecorderBottleneckDetector\n",
    "\n",
    "bottleneck_detector = RecorderBottleneckDetector(\n",
    "    logger=recorder_analyzer.logger,\n",
    "    log_dir=log_dir,\n",
    ")\n",
    "\n",
    "bottleneck_detector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is where our nested loops lie. The output type is `{view_type: bottleneck_dict}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "bottlenecks = bottleneck_detector.detect_bottlenecks(\n",
    "    views=views,\n",
    "    view_types=VIEW_TYPES,\n",
    ")\n",
    "\n",
    "len(bottlenecks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following saves the bottlenecks per `view_type`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "recorder_analyzer.save_bottlenecks(log_dir=log_dir, bottlenecks=bottlenecks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iopp",
   "language": "python",
   "name": "iopp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
