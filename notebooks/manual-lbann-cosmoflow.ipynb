{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 442 µs (started: 2023-03-06 17:51:48 -08:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 714 µs (started: 2023-03-06 17:51:48 -08:00)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some logs are stored in VAST with some stored in GPFS.\n",
    "\n",
    "Set `log_dir` to `/vast1/` when running the notebook on Quartz, otherwise use `/gpfs1/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.27 ms (started: 2023-03-06 17:51:48 -08:00)\n"
     ]
    }
   ],
   "source": [
    "#log_dir = \"/p/gpfs1/iopp/recorder_app_logs/cm1/nodes-32/workflow-4/_parquet\"\n",
    "# log_dir = \"/p/gpfs1/iopp/recorder_app_logs/hacc|/nodes-32/workflow-0/_parquet\"\n",
    "#log_dir = \"/p/gpfs1/iopp/recorder_app_logs/montage/nodes-32/_parquet\"\n",
    "#log_dir = \"/p/gpfs1/iopp/recorder_app_logs/montage_pegasus/nodes-32/_parquet\"\n",
    "log_dir = \"/p/gpfs1/iopp/recorder_app_logs/lbann-cosmoflow/nodes-32/_parquet\" # FIXME\n",
    "#log_dir = \"/p/gpfs1/iopp/recorder_app_logs/mummi-wemul/nodes-32-ppn-32/_parquet\"# FIXME\n",
    "# log_dir = \"/p/gpfs1/iopp/recorder_app_logs/lbann-jag/nodes-32/_parquet\"\n",
    "#log_dir = \"/p/gpfs1/iopp/recorder_app_logs/genome_pegasus/nodes-32/_parquet\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RecorderAnalyzer` is the main part that initializes the cluster. It creates `LocalCluster` or `LSFCluster` depending on the `force_local` variable. When it is set to `true`, it will just create a `LocalCluster`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wisio.recorder.RecorderAnalyzer at 0x20002e355748>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.95 s (started: 2023-03-06 17:51:48 -08:00)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from wisio.recorder import VIEW_TYPES, RecorderAnalyzer\n",
    "\n",
    "recorder_analyzer = RecorderAnalyzer(\n",
    "    cluster_manager_args=dict(\n",
    "#         force_local=True,\n",
    "        cluster_settings=dict(\n",
    "#             cores=32,\n",
    "            dashboard_port=3646,\n",
    "            local_directory=\"/var/tmp/dask-recorder\",\n",
    "            log_file=\"%J.log\",\n",
    "#             memory=3200,\n",
    "            worker_queue=\"pdebug\"\n",
    "        )\n",
    "    ),\n",
    "    working_dir='.recorder',\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "recorder_analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://192.168.65.58:3646/status']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.87 ms (started: 2023-03-06 17:51:57 -08:00)\n"
     ]
    }
   ],
   "source": [
    "[client.dashboard_link for client in recorder_analyzer.cluster_manager.clients]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point on, every step is exactly the same within the `analyze_parquet` method of `RecorderAnalyzer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_id': [-9223019127069887826, 9223057279186121517],\n",
       " 'proc_id': [5117778030848120071, 5117778030855975832],\n",
       " 'tmid': [0, 120231585016530]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.42 ms (started: 2023-03-06 17:52:22 -08:00)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "global_min_max = recorder_analyzer.load_global_min_max(log_dir=log_dir)\n",
    "global_min_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 945 µs (started: 2023-03-06 17:52:22 -08:00)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from wisio._recorder.analysis import (\n",
    "    compute_main_view,\n",
    "    compute_max_io_time,\n",
    "    compute_view\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compute_main_view` automatically does `persist` before returning the DataFrame. You may play with that part if the `main_view` doesn't fit within the allocated memory. That said, `persist`ing it increases performance significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trange</th>\n",
       "      <th>file_id</th>\n",
       "      <th>proc_id</th>\n",
       "      <th>io_cat</th>\n",
       "      <th>acc_pat</th>\n",
       "      <th>duration_sum</th>\n",
       "      <th>index_count</th>\n",
       "      <th>size_min</th>\n",
       "      <th>size_max</th>\n",
       "      <th>size_sum</th>\n",
       "      <th>file_name</th>\n",
       "      <th>proc_name</th>\n",
       "      <th>func_id</th>\n",
       "      <th>read_time</th>\n",
       "      <th>write_time</th>\n",
       "      <th>metadata_time</th>\n",
       "      <th>read_size</th>\n",
       "      <th>write_size</th>\n",
       "      <th>metadata_size</th>\n",
       "      <th>read_count</th>\n",
       "      <th>write_count</th>\n",
       "      <th>metadata_count</th>\n",
       "      <th>data_count</th>\n",
       "      <th>data_size</th>\n",
       "      <th>data_time</th>\n",
       "      <th>sequential_time</th>\n",
       "      <th>random_time</th>\n",
       "      <th>sequential_size</th>\n",
       "      <th>random_size</th>\n",
       "      <th>sequential_count</th>\n",
       "      <th>random_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float32</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: rename, 1 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              trange file_id proc_id io_cat acc_pat duration_sum index_count size_min size_max size_sum file_name proc_name func_id read_time write_time metadata_time read_size write_size metadata_size read_count write_count metadata_count data_count data_size data_time sequential_time random_time sequential_size random_size sequential_count random_count\n",
       "npartitions=1                                                                                                                                                                                                                                                                                                                                                       \n",
       "               int64   int64   int64  int64   int64      float32       int64    int64    int64    int64    object    object  object     int64      int64         int64     int64      int64         int64      int64       int64          int64      int64     int64     int64           int64       int64           int64       int64            int64        int64\n",
       "                 ...     ...     ...    ...     ...          ...         ...      ...      ...      ...       ...       ...     ...       ...        ...           ...       ...        ...           ...        ...         ...            ...        ...       ...       ...             ...         ...             ...         ...              ...          ...\n",
       "Dask Name: rename, 1 tasks"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.77 s (started: 2023-03-06 17:52:23 -08:00)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "main_view = compute_main_view(\n",
    "    log_dir=log_dir,\n",
    "    global_min_max=global_min_max,\n",
    "    view_types=VIEW_TYPES\n",
    ")\n",
    "\n",
    "main_view\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_io_time` is just a `dd.Scalar` since I tried to compute everyting lazily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dd.Scalar<series-..., dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 652 ms (started: 2023-03-06 17:52:52 -08:00)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "max_io_time = compute_max_io_time(main_view=main_view)\n",
    "max_io_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may configure `delta` and `cut` using the following variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 781 µs (started: 2023-03-06 17:53:34 -08:00)\n"
     ]
    }
   ],
   "source": [
    "DELTA = 0.0001\n",
    "CUT = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is how all the views (including `expanded_view` and `bottleneck_view`-I didn't like the `cut_view` name). So, if you want to play with that part `compute_view` is the method you should look for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.1 s (started: 2023-03-06 17:59:24 -08:00)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "def _view_permutations(r: int):\n",
    "    return it.permutations(VIEW_TYPES, r + 1)\n",
    "\n",
    "views = {}\n",
    "for view_permutation in it.chain.from_iterable(map(_view_permutations, range(len(VIEW_TYPES)))):\n",
    "    # Compute view\n",
    "    views[view_permutation] = compute_view(\n",
    "        main_view=main_view,\n",
    "        views=views,\n",
    "        view_permutation=view_permutation,\n",
    "        max_io_time=max_io_time,\n",
    "        delta=DELTA,\n",
    "        cut=CUT\n",
    "    )\n",
    "\n",
    "\n",
    "len(views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following just initializes the bottleneck detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wisio._recorder.bottlenecks.RecorderBottleneckDetector at 0x20004a3ea320>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.53 ms (started: 2023-03-06 17:59:35 -08:00)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from wisio._recorder.bottlenecks import RecorderBottleneckDetector\n",
    "\n",
    "bottleneck_detector = RecorderBottleneckDetector(\n",
    "    logger=recorder_analyzer.logger,\n",
    "    log_dir=log_dir,\n",
    ")\n",
    "\n",
    "bottleneck_detector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is where our nested loops lie. The output type is `{view_type: bottleneck_dict}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "bottlenecks = bottleneck_detector.detect_bottlenecks(\n",
    "    views=views,\n",
    "    view_types=VIEW_TYPES,\n",
    ")\n",
    "\n",
    "len(bottlenecks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following saves the bottlenecks per `view_type`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "recorder_analyzer.save_bottlenecks(log_dir=log_dir, bottlenecks=bottlenecks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digio-virenv-lassen",
   "language": "python",
   "name": "digio-virenv-lassen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
